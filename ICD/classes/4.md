## PCA (Prinicpal Component Analysis)

PCA se usa mas solo en aprendizaje supervisado

Reducir la cantidad de variables a través de una técnica llamada **PCA**
P es el cantidad original de dimenciones y z es la cantidad de variables que queremos

La total de varianza del dataset original, yo quiero explciar la mayor cantidad de varianza posible en el nuevo espacio de dimenciones

Tienes 1k features y decides teneer sol0 100 componentes (a ciegas, empiritico) no se sabe si este nuevo espcio preserva una cantidad importante de patrones latentes del espcio original, loq ue se hace es, cojer el primer component y ver el porc de varianza, asi con el segundo componente y vas sumando. Esa suma total de porcentajes deberia dar un alderedeor del 80% 

![](../assets/CleanShot%202021-07-21%20at%2011.30.13.png)

```python
from scklean.descomposicion import PCA

pca = PCA(n_components=3).fit(X)
X = pca.transform(X)

pca_std =PCA(n_components=3).fit(X)
X = pca_std.transform(X) #mucho mejor estadarizado!!

explained_cariance_ratio = pca.explained_variance_ratio_
cum_explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)
lst = []
for i in range(0, n_components):
  lst.append([i+1, round(explained_cariance_ratio[i], 6), cum_explained_variance_ratio[i]])

pca_pre = pd.DataFrame(lst)
pca_predictor.columns = ['Component', 'Explained_variance_ratio', 'Cum Explained Variance_ratio']
pca_predictor
```

## Limitationes
- Solo supervisado
- Explainability, no se puede caracterizar las instancias 

Pairplots visualicion de features para los features nuevos (los reducidos)